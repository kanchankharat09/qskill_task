# -*- coding: utf-8 -*-
"""banglore_housepricePproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mFmZ46AnGvTgtTSTWkj9tj1Qpoj7OaQs
"""

import pandas as pd #  use for data clening
import numpy as np # use ,arry,math ,staticstic,missing value(np.nan)
from matplotlib import pyplot as plt # use for data vizulization make line garph ,bar chart,histogram
import matplotlib                             #\
matplotlib.rcParams['figure.figsize']=(20,10)# / chages the defult plot size make your plot larger and easier to see
                                             # (20,10) is wideth and hight in inches

df1=pd.read_csv('/content/bengaluru_house_prices.csv')
df1.head()

"""checking the how many rows and columns"""

df1.shape
# (13320, 9)
#   rows,columns

"""checking the names of the columns"""

df1.columns
#  dytpe=object â†’ anything else (usually strings)

"""checlikng the 1st column by .unique() Shows all unique values (no repeats)

"""

df1['area_type'].unique()



""".value_counts() â†’ Shows how often values are appear
 Understand what's inside
ðŸ§¹ Clean unusual, rare, or messy values
"""

df1['area_type'].value_counts()

# so here in value count wefind that super built upa rae values are more compair to other values and their are only fouretype so it will not tech ml model tthat much info and other type have very less value count comapir to superbuiltup are so it will not balce the result so we are dropping the area type and also squre foot show thwe area and the price also so ml can get info from this that whay

df1.columns

"""so we are droping the the columns which we find no use in this
Drop features that are not required to build our model


"""

df2=df1.drop(['area_type','availability','balcony','society'],axis='columns')
# axis =column means drop thatthes columns

df2.head(3)

"""### data cleaning :handling NAvalues"""

df2.isnull().sum()

# these are the na values so my data set is big and the no of na values
# is small so i will drop the na values

df3 = df2.dropna()
df3.isnull().sum()
# so i drop the na values

df3.shape

df3['location'].unique()
# loction can be diffrant and can be reapeat so no varry

df3['size'].unique()

df3['size'].value_counts()

# we can see that some value written un bhk soem are in4 beadroom

"""feature enginnering so we are goung to add new column in the df3"""

df3['bhk']=df3['size'].apply(lambda x:int(x.split(' ')[0]))

#A lambda is a short, anonymous function (function without a name) used for quick one-liner logic.

# Itâ€™s used when you donâ€™t want to write a full def function.
# what we do heare we split x so x become the values so we split them frfisrt value so we written[0om space('') and we tell taht
# omly take fisrt value i.e[0] then thisis str so we convert it into int()

df3.head(4)

# we can see herea teh bhk the new column

# after size the next column is total_sqft we will check the unuque valuein it

df3['bhk'].unique()

df3[df3.bhk>20]  # we are finding houses with more that 20 bedrooms

# 43 b3droom house total sqft area is 2400 is look like aerror

# so check f3.total_sqft.unique values in df3

df3.total_sqft.unique()

# what we find here is some value are single but soem are two showing range

# going to make funcation whare the it will detect the flot if it return flae if  tryue it will write true valye

def is_float(x):
  try:
    float(x)
  except:
    return False
  return True

# it will try to make values float if they finfd error except willcahech the error nad return false
#What does except do in is_float()?
# It catches the error if a value canâ€™t be converted to float, so the function can return False instead of crashing.

# so we want the value which is float but ~ this sing make it
# opsite it will so the value which are not float

"""What does ~ mean in pandas? In pandas, ~ means "not".

It is used to reverse a condition (like not in plain Python).

New Section
This means:

"Give me the rows where 'total_sqft' is NOT a float."
"""

df3[~df3['total_sqft'].apply(is_float)].head(10)


# so we are the def fun to this whre it will oppposite tehre reasult it will shoe the value which are not float

"""Above shows that total_sqft can be a range (e.g. 2100-2850). For such case we can just take average of min and max value in the range. There are other cases such as 34.46Sq. Meter which one can convert to square ft using unit conversion. I am going to just drop such corner cases to keep things simple:"""

# by this we get to know their in df3 total sqft what types of values re tehir so we can use what type of methid to correct it

# for that we use def  two split range for the normal no and try and for 123.sqrt like this no wee use term except

def covert_sqft_to_num(x):
  token=x.split('-')
  if len(token)==2:
     return (float(token[0])+float(token[1]))/2
  try:
    return  float(x)
  except:
    return None

# made funcation by using token =x.split(-) split the value from '-' sigh
# so now length of token value is ==2 then take flaot of taken value 0 and flaot of 1 token value add these
# and then divide it by 2 so we calulate  mean of the value which in range 1200-1234
# try return float(x)so the value is like 1234 single value then conver t it in to flot
#  use except is the value is not lke abbove two 1234.5sqer like this then except the error but dont do anyting

covert_sqft_to_num('1195') #used try flaot(x)

covert_sqft_to_num('1015 - 1540')# so if token ==2

covert_sqft_to_num('34.46Sq. Meter') # used except here so it return none

"""#so we are apply this function to total_sqft column

"""

df4=df3.copy()
df4['total_sqft']=df3['total_sqft'].apply(covert_sqft_to_num)
df4.head(3)

# frature enginning to make pride per seft column it
# made copy of df4 is df5 inthis df 5 make a column price per sqft like this doing price/total sqft but the ubit is not sma
# *100000 then divide it by total sqft
# new couln in df5 'price_per_sqft'named

df5=df4.copy()
df5['price_per_sqft']=df5['price']*100000/df5['total_sqft']
df5.head(4)

df5.location.unique()

#  we care checking some unique locations in the location co,umn

len(df5.location.unique())

# we are checking how many unique location are their so their are may unique location so it willbe very hard for ml to the handling

# we are going to make the one grop of this new location naming it other

# in ml we only need clen data to make easy for the model so if we group this data the 1. To Save Space & Avoid Too Many Columns
#2. To Make the Model Run Faster & Generalize Better

"""#Think of it Like This:
If a location appears only once, it doesnâ€™t teach the model much.

Itâ€™s smarter to group those few into one category: 'other'

This makes training faster, cleaner, and often gives better accuracy.
"""

# first we ae removing some extra speace from the loication

df5.location=df5.location.apply(lambda x:x.strip())

"""we make the location_stats whre we group the location and in that location we count how many values rows are in location column the we sort that by assending =false to make greter location row value apper fisr aand lower row values at thelast"""

location_stats=df5.groupby('location')['location'].agg('count').sort_values(ascending=False)
location_stats

# we are making like any location hsving less that 10 dta point that is values so lets called it otehr location

location_stats_less_than=location_stats[location_stats<=10]

# checking the lengh of location_stat
(location_stats[location_stats<=10])

location_stats_less_than_10=location_stats[location_stats<=10]
location_stats_less_than_10

len(df5.location.unique()) # what unique is so if the vesues
#  are repeted in df it will show it only one time
#  liek thisntype ofthem also present  in the df but it
#  now show the values repeteedy or simpole way only oneces show no duplicated show

# byapplying labdat we say call other in x in thatvvalues in location location_stats_less_than_10
# called it other and if its not les thatn = 10 then let it ebe x i.e origunal values

df5.location=df5.location.apply(lambda x:'other'if x in location_stats_less_than_10 else x)

#if we print the location values hwo much it will be so fist befor it was 1293
# after dong the less tahn 10 242 now
len(df5.location.unique())